{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Activation, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (width, height, depth)\n",
    "        chanDims = -1\n",
    "        model.add(Conv2D(8, (5, 5) ,padding = \"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDims))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#           conv-> relu-> conv-> relu-> pool\n",
    "        model.add(Conv2D(16, (3,3) , padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDims))\n",
    "        model.add(Conv2D(16, (3,3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDims))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#           conv-> relu-> conv-> relu-> pool           \n",
    "        model.add(Conv2D(32, (3,3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDims))\n",
    "        model.add(Conv2D(32, (3,3) ,padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDims))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#           1st set of FC layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "#           2nd set of FC layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "#           Softmax Classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage import transform\n",
    "from skimage import exposure\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(basePath, csvPath):\n",
    "\t# initialize the list of data and labels\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "\n",
    "\t# load the contents of the CSV file, remove the first line (since\n",
    "\t# it contains the CSV header), and shuffle the rows (otherwise\n",
    "\t# all examples of a particular class will be in sequential order)\n",
    "\trows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
    "\trandom.shuffle(rows)\n",
    "\n",
    "\t# loop over the rows of the CSV file\n",
    "\tfor (i, row) in enumerate(rows):\n",
    "\t\t# check to see if we should show a status update\n",
    "\t\tif i > 0 and i % 1000 == 0:\n",
    "\t\t\tprint(\"[INFO] processed {} total images\".format(i))\n",
    "\n",
    "\t\t# split the row into components and then grab the class ID\n",
    "\t\t# and image path\n",
    "\t\t(label, imagePath) = row.strip().split(\",\")[-2:]\n",
    "\n",
    "\t\t# derive the full path to the image file and load it\n",
    "\t\timagePath = os.path.sep.join([basePath, imagePath])\n",
    "\t\timage = io.imread(imagePath)\n",
    "\n",
    "\t\t# resize the image to be 32x32 pixels, ignoring aspect ratio,\n",
    "\t\t# and then perform Contrast Limited Adaptive Histogram\n",
    "\t\t# Equalization (CLAHE)\n",
    "\t\timage = transform.resize(image, (32, 32))\n",
    "\t\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
    "\n",
    "\t\t# update the list of data and labels, respectively\n",
    "\t\tdata.append(image)\n",
    "\t\tlabels.append(int(label))\n",
    "\n",
    "\t# convert the data and labels to NumPy arrays\n",
    "\tdata = np.array(data)\n",
    "\tlabels = np.array(labels)\n",
    "\n",
    "\t# return a tuple of the data and labels\n",
    "\treturn (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label names\n",
    "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Loading Dataset\n",
      "[INFO] processed 1000 total images\n",
      "[INFO] processed 2000 total images\n",
      "[INFO] processed 3000 total images\n",
      "[INFO] processed 4000 total images\n",
      "[INFO] processed 5000 total images\n",
      "[INFO] processed 6000 total images\n",
      "[INFO] processed 7000 total images\n",
      "[INFO] processed 8000 total images\n",
      "[INFO] processed 9000 total images\n",
      "[INFO] processed 10000 total images\n",
      "[INFO] processed 11000 total images\n",
      "[INFO] processed 12000 total images\n",
      "[INFO] processed 13000 total images\n",
      "[INFO] processed 14000 total images\n",
      "[INFO] processed 15000 total images\n",
      "[INFO] processed 16000 total images\n",
      "[INFO] processed 17000 total images\n",
      "[INFO] processed 18000 total images\n",
      "[INFO] processed 19000 total images\n",
      "[INFO] processed 20000 total images\n",
      "[INFO] processed 21000 total images\n",
      "[INFO] processed 22000 total images\n",
      "[INFO] processed 23000 total images\n",
      "[INFO] processed 24000 total images\n",
      "[INFO] processed 25000 total images\n",
      "[INFO] processed 26000 total images\n",
      "[INFO] processed 27000 total images\n",
      "[INFO] processed 28000 total images\n",
      "[INFO] processed 29000 total images\n",
      "[INFO] processed 30000 total images\n",
      "[INFO] processed 31000 total images\n",
      "[INFO] processed 32000 total images\n",
      "[INFO] processed 33000 total images\n",
      "[INFO] processed 34000 total images\n",
      "[INFO] processed 35000 total images\n",
      "[INFO] processed 36000 total images\n",
      "[INFO] processed 37000 total images\n",
      "[INFO] processed 38000 total images\n",
      "[INFO] processed 39000 total images\n",
      "[INFO] processed 1000 total images\n",
      "[INFO] processed 2000 total images\n",
      "[INFO] processed 3000 total images\n",
      "[INFO] processed 4000 total images\n",
      "[INFO] processed 5000 total images\n",
      "[INFO] processed 6000 total images\n",
      "[INFO] processed 7000 total images\n",
      "[INFO] processed 8000 total images\n",
      "[INFO] processed 9000 total images\n",
      "[INFO] processed 10000 total images\n",
      "[INFO] processed 11000 total images\n",
      "[INFO] processed 12000 total images\n",
      "End: Loaded Dataset\n",
      "TrainY :  [ 3 32 12 ... 10 38  3]\n"
     ]
    }
   ],
   "source": [
    "base = \"gtsrb-german-traffic-sign/\"\n",
    "trainPath = base + \"Train.csv\"\n",
    "testPath = base + \"Test.csv\"\n",
    "\n",
    "print(\"Start: Loading Dataset\")\n",
    "(trainX, trainY) = load_split(basePath= base, csvPath= trainPath)\n",
    "(testX, testY) = load_split(basePath= base, csvPath= testPath)\n",
    "print(\"End: Loaded Dataset\")\n",
    "print(\"TrainY : \", trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "trainXF = trainX.astype(\"float32\") / 255.0\n",
    "testXF = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n",
      "[ 3 32 12 ... 10 38  3]\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(trainY)))\n",
    "print(np.unique(trainY))\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the training and testing labels\n",
    "numLabels = len(np.unique(trainY))\n",
    "trainYF = to_categorical(trainY, numLabels)\n",
    "testYF = to_categorical(testY, numLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619047\n"
     ]
    }
   ],
   "source": [
    "print(trainY.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for skew in the labeled data\n",
    "classTotals = trainYF.sum(axis=0)\n",
    "classWeight = classTotals.max() / classTotals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4.342081949058693, 1: 0.41073748166771423, 2: 0.4052609819121447, 3: 0.6466930562427841, 4: 0.46052384308198263, 5: 0.49023505876469115, 6: 2.1710409745293466, 7: 0.6332202842377261, 8: 0.6466930562427841, 9: 0.620297421294099, 10: 0.45365035288672917, 11: 0.6907857646229739, 12: 0.4342081949058693, 13: 0.4221468561584841, 14: 1.1690220632081096, 15: 1.447360649686231, 16: 2.1710409745293466, 17: 0.8214749633354285, 18: 0.7598643410852713, 19: 4.342081949058693, 20: 2.5328811369509046, 21: 2.7631430584918957, 22: 2.3380441264162193, 23: 1.7879160966712266, 24: 3.3771748492678726, 25: 0.6078914728682171, 26: 1.5197286821705427, 27: 3.7993217054263564, 28: 1.6885874246339363, 29: 3.3771748492678726, 30: 2.0263049095607237, 31: 1.1690220632081096, 32: 3.7993217054263564, 33: 1.3234212036318223, 34: 2.1710409745293466, 35: 0.7598643410852713, 36: 2.3380441264162193, 37: 4.342081949058693, 38: 0.44050106729580946, 39: 3.0394573643410854, 40: 2.5328811369509046, 41: 3.7993217054263564, 42: 3.7993217054263564}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weight = class_weight.compute_class_weight('balanced', np.unique(trainY), trainY)\n",
    "weight = {i : weight[i] for i in range(43)}\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4.342081949058693, 1: 0.41073748166771423, 2: 0.4052609819121447, 3: 0.6466930562427841, 4: 0.46052384308198263, 5: 0.49023505876469115, 6: 2.1710409745293466, 7: 0.6332202842377261, 8: 0.6466930562427841, 9: 0.620297421294099, 10: 0.45365035288672917, 11: 0.6907857646229739, 12: 0.4342081949058693, 13: 0.4221468561584841, 14: 1.1690220632081096, 15: 1.447360649686231, 16: 2.1710409745293466, 17: 0.8214749633354285, 18: 0.7598643410852713, 19: 4.342081949058693, 20: 2.5328811369509046, 21: 2.7631430584918957, 22: 2.3380441264162193, 23: 1.7879160966712266, 24: 3.3771748492678726, 25: 0.6078914728682171, 26: 1.5197286821705427, 27: 3.7993217054263564, 28: 1.6885874246339363, 29: 3.3771748492678726, 30: 2.0263049095607237, 31: 1.1690220632081096, 32: 3.7993217054263564, 33: 1.3234212036318223, 34: 2.1710409745293466, 35: 0.7598643410852713, 36: 2.3380441264162193, 37: 4.342081949058693, 38: 0.44050106729580946, 39: 3.0394573643410854, 40: 2.5328811369509046, 41: 3.7993217054263564, 42: 3.7993217054263564}\n"
     ]
    }
   ],
   "source": [
    "# temppppppppppppppppppppppp\n",
    "from sklearn.utils import class_weight\n",
    "weight = class_weight.compute_class_weight('balanced', np.unique(trainY), trainY)\n",
    "weight = {i : weight[i] for i in range(43)}\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10.714286, 1: 1.0135136, 2: 1.0, 3: 1.5957447, 4: 1.1363636, 5: 1.2096775, 6: 5.357143, 7: 1.5625, 8: 1.5957447, 9: 1.5306122, 10: 1.119403, 11: 1.7045455, 12: 1.0714285, 13: 1.0416666, 14: 2.8846154, 15: 3.5714285, 16: 5.357143, 17: 2.0270271, 18: 1.875, 19: 10.714286, 20: 6.25, 21: 6.818182, 22: 5.769231, 23: 4.4117646, 24: 8.333333, 25: 1.5, 26: 3.75, 27: 9.375, 28: 4.1666665, 29: 8.333333, 30: 5.0, 31: 2.8846154, 32: 9.375, 33: 3.2656024, 34: 5.357143, 35: 1.875, 36: 5.769231, 37: 10.714286, 38: 1.0869565, 39: 7.5, 40: 6.25, 41: 9.375, 42: 9.375}\n"
     ]
    }
   ],
   "source": [
    "ActualWeight = {}\n",
    "for (i,v) in enumerate(classWeight):\n",
    "    ActualWeight[i] = v\n",
    "print(ActualWeight)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.714286   1.0135136  1.         1.5957447  1.1363636  1.2096775\n",
      "  5.357143   1.5625     1.5957447  1.5306122  1.119403   1.7045455\n",
      "  1.0714285  1.0416666  2.8846154  3.5714285  5.357143   2.0270271\n",
      "  1.875     10.714286   6.25       6.818182   5.769231   4.4117646\n",
      "  8.333333   1.5        3.75       9.375      4.1666665  8.333333\n",
      "  5.         2.8846154  9.375      3.2656024  5.357143   1.875\n",
      "  5.769231  10.714286   1.0869565  7.5        6.25       9.375\n",
      "  9.375    ]\n"
     ]
    }
   ],
   "source": [
    "print(classWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=10,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=False,\n",
    "\tvertical_flip=False,\n",
    "\tfill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Compile Model\n",
      "End: Compile Model\n"
     ]
    }
   ],
   "source": [
    "# compiling model\n",
    "NUM_EPOCHS = 5\n",
    "print(\"Start: Compile Model\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
    "model = TrafficSignNet.build(width = 32, height=32, depth=3, classes=numLabels)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics = [\"accuracy\"])\n",
    "print(\"End: Compile Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Training of network\n",
      "Epoch 1/5\n",
      "612/612 [==============================] - 46s 75ms/step - loss: 2.6515 - accuracy: 0.2922 - val_loss: 2.7415 - val_accuracy: 0.2298\n",
      "Epoch 2/5\n",
      "612/612 [==============================] - 49s 79ms/step - loss: 1.4798 - accuracy: 0.5269 - val_loss: 13.0393 - val_accuracy: 0.0625\n",
      "Epoch 3/5\n",
      "612/612 [==============================] - 51s 84ms/step - loss: 1.0661 - accuracy: 0.6568 - val_loss: 7.7383 - val_accuracy: 0.1279\n",
      "Epoch 4/5\n",
      "612/612 [==============================] - 49s 80ms/step - loss: 0.8210 - accuracy: 0.7368 - val_loss: 14.5826 - val_accuracy: 0.0283\n",
      "Epoch 5/5\n",
      "612/612 [==============================] - 74s 121ms/step - loss: 0.6868 - accuracy: 0.7763 - val_loss: 2.1141 - val_accuracy: 0.4706\n",
      "End: Training of network\n"
     ]
    }
   ],
   "source": [
    "# training the networ Training of network\")\n",
    "print(\"Start: Training of network\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainXF, trainYF, batch_size=BS),\n",
    "\tvalidation_data=(testXF, testYF),\n",
    "\tsteps_per_epoch=trainXF.shape[0] // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "# \tclass_weight=ActualWeight,\n",
    "\tverbose=1)\n",
    "print(\"End: Training of network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Evaluate network\n",
      "                                                    precision    recall  f1-score   support\n",
      "\n",
      "                              Speed limit (20km/h)       0.00      0.00      0.00        60\n",
      "                              Speed limit (30km/h)       0.86      0.19      0.32       720\n",
      "                              Speed limit (50km/h)       0.89      0.08      0.15       750\n",
      "                              Speed limit (60km/h)       0.75      0.17      0.28       450\n",
      "                              Speed limit (70km/h)       0.68      0.19      0.29       660\n",
      "                              Speed limit (80km/h)       0.36      0.27      0.31       630\n",
      "                       End of speed limit (80km/h)       0.30      0.21      0.25       150\n",
      "                             Speed limit (100km/h)       0.21      0.36      0.27       450\n",
      "                             Speed limit (120km/h)       0.16      0.68      0.26       450\n",
      "                                        No passing       1.00      0.03      0.06       480\n",
      "      No passing for vehicles over 3.5 metric tons       0.70      0.74      0.72       660\n",
      "             Right-of-way at the next intersection       0.89      0.65      0.75       420\n",
      "                                     Priority road       0.99      0.68      0.81       690\n",
      "                                             Yield       0.95      0.85      0.90       720\n",
      "                                              Stop       1.00      0.62      0.77       270\n",
      "                                       No vehicles       1.00      0.10      0.17       210\n",
      "          Vehicles over 3.5 metric tons prohibited       0.31      0.70      0.43       150\n",
      "                                          No entry       0.96      0.84      0.89       360\n",
      "                                   General caution       0.78      0.42      0.55       390\n",
      "                       Dangerous curve to the left       0.00      0.00      0.00        60\n",
      "                      Dangerous curve to the right       0.28      0.46      0.34        90\n",
      "                                      Double curve       0.50      0.01      0.02        90\n",
      "                                        Bumpy road       0.90      0.16      0.27       120\n",
      "                                     Slippery road       1.00      0.01      0.03       150\n",
      "                         Road narrows on the right       0.17      0.01      0.02        90\n",
      "                                         Road work       0.48      0.75      0.59       480\n",
      "                                   Traffic signals       0.95      0.40      0.56       180\n",
      "                                       Pedestrians       0.88      0.12      0.21        60\n",
      "                                 Children crossing       0.71      0.30      0.42       150\n",
      "                                 Bicycles crossing       1.00      0.10      0.18        90\n",
      "                                Beware of ice/snow       0.28      0.47      0.35       150\n",
      "                             Wild animals crossing       0.61      0.66      0.63       270\n",
      "               End of all speed and passing limits       0.00      0.00      0.00        60\n",
      "                                  Turn right ahead       0.90      0.74      0.81       210\n",
      "                                   Turn left ahead       0.46      0.82      0.59       120\n",
      "                                        Ahead only       0.90      0.51      0.65       390\n",
      "                              Go straight or right       0.90      0.68      0.77       120\n",
      "                               Go straight or left       0.30      0.92      0.45        60\n",
      "                                        Keep right       0.40      0.99      0.57       690\n",
      "                                         Keep left       0.40      0.97      0.56        90\n",
      "                              Roundabout mandatory       0.07      0.90      0.13        90\n",
      "                                 End of no passing       0.67      0.07      0.12        60\n",
      "End of no passing by vehicles over 3.5 metric tons       0.60      0.10      0.17        90\n",
      "\n",
      "                                          accuracy                           0.47     12630\n",
      "                                         macro avg       0.61      0.42      0.39     12630\n",
      "                                      weighted avg       0.69      0.47      0.46     12630\n",
      "\n",
      "End: Evaluate network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parthjardosh/anaconda3/envs/TSC/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluatiing the network on the test set\n",
    "print(\"Start: Evaluate network\")\n",
    "predictions = model.predict(testXF, batch_size=BS)\n",
    "print(classification_report(testYF.argmax(axis=1), predictions.argmax(axis=1),target_names=labelNames))\n",
    "print(\"End: Evaluate network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Save the model\n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "print(\"Start: Save the model\")\n",
    "model.save(\"output/trafficsignnet\" + str(NUM_EPOCHS) +\".model\")\n",
    "print(\"End: Save the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, NUM_EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"output/plot\" + str(NUM_EPOCHS) +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
