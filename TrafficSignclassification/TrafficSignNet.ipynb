{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TrafficSignNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztAr6oN88l5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/open?id=1XOOqekwTs85QB25HQcA802U-gkGVgkex: drive link for the code folder\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "download = drive.CreateFile({'id': '1Z-JgPGF2SNb8litfIpL7S40g9LR5_F5L'})\n",
        "download.GetContentFile('gtsrb-german-traffic-sign.zip')\n",
        "!unzip gtsrb-german-traffic-sign.zip -d gtsrb-german-traffic-sign\n",
        "\n",
        "download = drive.CreateFile({'id': '1KB5C3gupn40Bj6ggIGJSKOy--xrmlHPS'})\n",
        "download.GetContentFile('signnames.csv')\n",
        "!unzip gtsrb-german-traffic-sign.zip -d gtsrb-german-traffic-sign\n",
        "OutputFolder = \"/content/output/\"\n",
        "ProjectName = \"TrafficSignNet\"\n",
        "DriveOutputFolder = \"drive/My\\ Drive/Colab\\ Notebooks/DLProjects/\" + ProjectName +\"/output/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdXZHyTo_3I5",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENFgfqv22nG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the required libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Activation, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3dQfFJ2nHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrafficSignNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        model = Sequential()\n",
        "        inputShape = (width, height, depth)\n",
        "        chanDims = -1\n",
        "        model.add(Conv2D(8, (5, 5) ,padding = \"same\", input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDims))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#           conv-> relu-> conv-> relu-> pool\n",
        "        model.add(Conv2D(16, (3,3) , padding = \"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDims))\n",
        "        model.add(Conv2D(16, (3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDims))\n",
        "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#           conv-> relu-> conv-> relu-> pool           \n",
        "        model.add(Conv2D(32, (3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDims))\n",
        "        model.add(Conv2D(32, (3,3) ,padding = \"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDims))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#           1st set of FC layer\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "#           2nd set of FC layer\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "#           Softmax Classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        \n",
        "        \n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCRPaA-2nHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage import transform\n",
        "from skimage import exposure\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yk8564K2nHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_split(basePath, csvPath):\n",
        "\t# initialize the list of data and labels\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\n",
        "\t# load the contents of the CSV file, remove the first line (since\n",
        "\t# it contains the CSV header), and shuffle the rows (otherwise\n",
        "\t# all examples of a particular class will be in sequential order)\n",
        "\trows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
        "\trandom.shuffle(rows)\n",
        "\n",
        "\t# loop over the rows of the CSV file\n",
        "\tfor (i, row) in enumerate(rows):\n",
        "\t\t# check to see if we should show a status update\n",
        "\t\tif i > 0 and i % 1000 == 0:\n",
        "\t\t\tprint(\"[INFO] processed {} total images\".format(i))\n",
        "\n",
        "\t\t# split the row into components and then grab the class ID\n",
        "\t\t# and image path\n",
        "\t\t(label, imagePath) = row.strip().split(\",\")[-2:]\n",
        "\n",
        "\t\t# derive the full path to the image file and load it\n",
        "\t\timagePath = os.path.sep.join([basePath, imagePath])\n",
        "\t\timage = io.imread(imagePath)\n",
        "\n",
        "\t\t# resize the image to be 32x32 pixels, ignoring aspect ratio,\n",
        "\t\t# and then perform Contrast Limited Adaptive Histogram\n",
        "\t\t# Equalization (CLAHE)\n",
        "\t\timage = transform.resize(image, (32, 32))\n",
        "\t\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
        "\n",
        "\t\t# update the list of data and labels, respectively\n",
        "\t\tdata.append(image)\n",
        "\t\tlabels.append(int(label))\n",
        "\n",
        "\t# convert the data and labels to NumPy arrays\n",
        "\tdata = np.array(data)\n",
        "\tlabels = np.array(labels)\n",
        "\n",
        "\t# return a tuple of the data and labels\n",
        "\treturn (data, labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZRtEYf2nHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the number of epochs to train for, base learning rate,\n",
        "# and batch size\n",
        "NUM_EPOCHS = 30\n",
        "INIT_LR = 1e-3\n",
        "BS = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHGrVOq2nH0",
        "colab_type": "code",
        "outputId": "987d0d62-a062-4ec0-a144-6a468cd10aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# load the label names\n",
        "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
        "print(labelNames)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)', 'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)', 'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)', 'No passing', 'No passing for vehicles over 3.5 metric tons', 'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry', 'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing', 'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left', 'Roundabout mandatory', 'End of no passing', 'End of no passing by vehicles over 3.5 metric tons']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8HmqFEZ2nH7",
        "colab_type": "code",
        "outputId": "8210b213-d683-4f6c-b7f6-90ac865d5f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "base = \"gtsrb-german-traffic-sign/\"\n",
        "trainPath = base + \"Train.csv\"\n",
        "testPath = base + \"Test.csv\"\n",
        "\n",
        "print(\"Start: Loading Dataset\")\n",
        "(trainX, trainY) = load_split(basePath= base, csvPath= trainPath)\n",
        "(testX, testY) = load_split(basePath= base, csvPath= testPath)\n",
        "print(\"End: Loaded Dataset\")\n",
        "print(\"TrainY : \", trainY)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Loading Dataset\n",
            "[INFO] processed 1000 total images\n",
            "[INFO] processed 2000 total images\n",
            "[INFO] processed 3000 total images\n",
            "[INFO] processed 4000 total images\n",
            "[INFO] processed 5000 total images\n",
            "[INFO] processed 6000 total images\n",
            "[INFO] processed 7000 total images\n",
            "[INFO] processed 8000 total images\n",
            "[INFO] processed 9000 total images\n",
            "[INFO] processed 10000 total images\n",
            "[INFO] processed 11000 total images\n",
            "[INFO] processed 12000 total images\n",
            "[INFO] processed 13000 total images\n",
            "[INFO] processed 14000 total images\n",
            "[INFO] processed 15000 total images\n",
            "[INFO] processed 16000 total images\n",
            "[INFO] processed 17000 total images\n",
            "[INFO] processed 18000 total images\n",
            "[INFO] processed 19000 total images\n",
            "[INFO] processed 20000 total images\n",
            "[INFO] processed 21000 total images\n",
            "[INFO] processed 22000 total images\n",
            "[INFO] processed 23000 total images\n",
            "[INFO] processed 24000 total images\n",
            "[INFO] processed 25000 total images\n",
            "[INFO] processed 26000 total images\n",
            "[INFO] processed 27000 total images\n",
            "[INFO] processed 28000 total images\n",
            "[INFO] processed 29000 total images\n",
            "[INFO] processed 30000 total images\n",
            "[INFO] processed 31000 total images\n",
            "[INFO] processed 32000 total images\n",
            "[INFO] processed 33000 total images\n",
            "[INFO] processed 34000 total images\n",
            "[INFO] processed 35000 total images\n",
            "[INFO] processed 36000 total images\n",
            "[INFO] processed 37000 total images\n",
            "[INFO] processed 38000 total images\n",
            "[INFO] processed 39000 total images\n",
            "[INFO] processed 1000 total images\n",
            "[INFO] processed 2000 total images\n",
            "[INFO] processed 3000 total images\n",
            "[INFO] processed 4000 total images\n",
            "[INFO] processed 5000 total images\n",
            "[INFO] processed 6000 total images\n",
            "[INFO] processed 7000 total images\n",
            "[INFO] processed 8000 total images\n",
            "[INFO] processed 9000 total images\n",
            "[INFO] processed 10000 total images\n",
            "[INFO] processed 11000 total images\n",
            "[INFO] processed 12000 total images\n",
            "End: Loaded Dataset\n",
            "TrainY :  [ 1  2 11 ...  1  3 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU2LtKh92nIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling data\n",
        "trainXF = trainX.astype(\"float32\") / 255.0\n",
        "testXF = testX.astype(\"float32\") / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4eXvQxG2nIH",
        "colab_type": "code",
        "outputId": "2f5df44e-cfc5-4f67-b729-9fb87a957282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(len(np.unique(trainY)))\n",
        "print(np.unique(trainY))\n",
        "print(trainY)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n",
            "[ 1  2 11 ...  1  3 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udl_WUp72nIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encode the training and testing labels\n",
        "numLabels = len(np.unique(trainY))\n",
        "trainYF = to_categorical(trainY, numLabels)\n",
        "testYF = to_categorical(testY, numLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuYPTrpD2nIU",
        "colab_type": "code",
        "outputId": "4901499e-1237-4346-c846-cabc75a40b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(trainY.sum(axis=0))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "619047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EsDn4VH2nIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# account for skew in the labeled data\n",
        "classTotals = trainYF.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Gbx-7A2nIi",
        "colab_type": "code",
        "outputId": "02ed4899-16f4-4347-b80e-1fee599b2902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "weight = class_weight.compute_class_weight('balanced', np.unique(trainY), trainY)\n",
        "weight = {i : weight[i] for i in range(43)}\n",
        "print(weight)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 4.342081949058693, 1: 0.41073748166771423, 2: 0.4052609819121447, 3: 0.6466930562427841, 4: 0.46052384308198263, 5: 0.49023505876469115, 6: 2.1710409745293466, 7: 0.6332202842377261, 8: 0.6466930562427841, 9: 0.620297421294099, 10: 0.45365035288672917, 11: 0.6907857646229739, 12: 0.4342081949058693, 13: 0.4221468561584841, 14: 1.1690220632081096, 15: 1.447360649686231, 16: 2.1710409745293466, 17: 0.8214749633354285, 18: 0.7598643410852713, 19: 4.342081949058693, 20: 2.5328811369509046, 21: 2.7631430584918957, 22: 2.3380441264162193, 23: 1.7879160966712266, 24: 3.3771748492678726, 25: 0.6078914728682171, 26: 1.5197286821705427, 27: 3.7993217054263564, 28: 1.6885874246339363, 29: 3.3771748492678726, 30: 2.0263049095607237, 31: 1.1690220632081096, 32: 3.7993217054263564, 33: 1.3234212036318223, 34: 2.1710409745293466, 35: 0.7598643410852713, 36: 2.3380441264162193, 37: 4.342081949058693, 38: 0.44050106729580946, 39: 3.0394573643410854, 40: 2.5328811369509046, 41: 3.7993217054263564, 42: 3.7993217054263564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH-93Rk52nIq",
        "colab_type": "code",
        "outputId": "e0262fbd-a28a-4bb0-fa07-574be75b7ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# temppppppppppppppppppppppp\n",
        "from sklearn.utils import class_weight\n",
        "weight = class_weight.compute_class_weight('balanced', np.unique(trainY), trainY)\n",
        "weight = {i : weight[i] for i in range(43)}\n",
        "print(weight)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 4.342081949058693, 1: 0.41073748166771423, 2: 0.4052609819121447, 3: 0.6466930562427841, 4: 0.46052384308198263, 5: 0.49023505876469115, 6: 2.1710409745293466, 7: 0.6332202842377261, 8: 0.6466930562427841, 9: 0.620297421294099, 10: 0.45365035288672917, 11: 0.6907857646229739, 12: 0.4342081949058693, 13: 0.4221468561584841, 14: 1.1690220632081096, 15: 1.447360649686231, 16: 2.1710409745293466, 17: 0.8214749633354285, 18: 0.7598643410852713, 19: 4.342081949058693, 20: 2.5328811369509046, 21: 2.7631430584918957, 22: 2.3380441264162193, 23: 1.7879160966712266, 24: 3.3771748492678726, 25: 0.6078914728682171, 26: 1.5197286821705427, 27: 3.7993217054263564, 28: 1.6885874246339363, 29: 3.3771748492678726, 30: 2.0263049095607237, 31: 1.1690220632081096, 32: 3.7993217054263564, 33: 1.3234212036318223, 34: 2.1710409745293466, 35: 0.7598643410852713, 36: 2.3380441264162193, 37: 4.342081949058693, 38: 0.44050106729580946, 39: 3.0394573643410854, 40: 2.5328811369509046, 41: 3.7993217054263564, 42: 3.7993217054263564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP_rxPxh2nIv",
        "colab_type": "code",
        "outputId": "8f7bc78c-4402-4fc0-bcc0-866a461f93ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "ActualWeight = {}\n",
        "for (i,v) in enumerate(classWeight):\n",
        "    ActualWeight[i] = v\n",
        "print(ActualWeight)    "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 10.714286, 1: 1.0135136, 2: 1.0, 3: 1.5957447, 4: 1.1363636, 5: 1.2096775, 6: 5.357143, 7: 1.5625, 8: 1.5957447, 9: 1.5306122, 10: 1.119403, 11: 1.7045455, 12: 1.0714285, 13: 1.0416666, 14: 2.8846154, 15: 3.5714285, 16: 5.357143, 17: 2.0270271, 18: 1.875, 19: 10.714286, 20: 6.25, 21: 6.818182, 22: 5.769231, 23: 4.4117646, 24: 8.333333, 25: 1.5, 26: 3.75, 27: 9.375, 28: 4.1666665, 29: 8.333333, 30: 5.0, 31: 2.8846154, 32: 9.375, 33: 3.2656024, 34: 5.357143, 35: 1.875, 36: 5.769231, 37: 10.714286, 38: 1.0869565, 39: 7.5, 40: 6.25, 41: 9.375, 42: 9.375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3MvF4-i2nI2",
        "colab_type": "code",
        "outputId": "9c41163f-2d27-486a-c325-013f74c879b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(classWeight)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10.714286   1.0135136  1.         1.5957447  1.1363636  1.2096775\n",
            "  5.357143   1.5625     1.5957447  1.5306122  1.119403   1.7045455\n",
            "  1.0714285  1.0416666  2.8846154  3.5714285  5.357143   2.0270271\n",
            "  1.875     10.714286   6.25       6.818182   5.769231   4.4117646\n",
            "  8.333333   1.5        3.75       9.375      4.1666665  8.333333\n",
            "  5.         2.8846154  9.375      3.2656024  5.357143   1.875\n",
            "  5.769231  10.714286   1.0869565  7.5        6.25       9.375\n",
            "  9.375    ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppY0zqyh2nI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=10,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=False,\n",
        "\tvertical_flip=False,\n",
        "\tfill_mode=\"nearest\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQAl3f3_2nJB",
        "colab_type": "code",
        "outputId": "5137687b-648b-43cd-b6f9-c2c63876ec08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# compiling model\n",
        "# NUM_EPOCHS = 5\n",
        "print(\"Start: Compile Model\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
        "model = TrafficSignNet.build(width = 32, height=32, depth=3, classes=numLabels)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics = [\"accuracy\"])\n",
        "print(\"End: Compile Model\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Compile Model\n",
            "End: Compile Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jD-p6Wg22nJF",
        "colab_type": "code",
        "outputId": "2094e6bd-c44e-41aa-c460-4b49d04abca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training the networ Training of network\")\n",
        "print(\"Start: Training of network\")\n",
        "H = model.fit_generator(\n",
        "\taug.flow(trainXF, trainYF, batch_size=BS),\n",
        "\tvalidation_data=(testXF, testYF),\n",
        "\tsteps_per_epoch=trainXF.shape[0] // BS,\n",
        "\tepochs=NUM_EPOCHS,\n",
        "\tclass_weight=ActualWeight,\n",
        "\tverbose=1)\n",
        "print(\"End: Training of network\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Training of network\n",
            "WARNING:tensorflow:From <ipython-input-36-e160793f07b7>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 7.7815 - accuracy: 0.1643 - val_loss: 3.2634 - val_accuracy: 0.1931\n",
            "Epoch 2/30\n",
            "612/612 [==============================] - 30s 48ms/step - loss: 4.4672 - accuracy: 0.4062 - val_loss: 1.3142 - val_accuracy: 0.5550\n",
            "Epoch 3/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 3.1500 - accuracy: 0.5510 - val_loss: 0.8487 - val_accuracy: 0.7044\n",
            "Epoch 4/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 2.3704 - accuracy: 0.6417 - val_loss: 1.0710 - val_accuracy: 0.6311\n",
            "Epoch 5/30\n",
            "612/612 [==============================] - 30s 48ms/step - loss: 1.9095 - accuracy: 0.7051 - val_loss: 0.5347 - val_accuracy: 0.8136\n",
            "Epoch 6/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 1.5758 - accuracy: 0.7490 - val_loss: 0.4878 - val_accuracy: 0.8298\n",
            "Epoch 7/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 1.3845 - accuracy: 0.7788 - val_loss: 0.4239 - val_accuracy: 0.8538\n",
            "Epoch 8/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 1.1834 - accuracy: 0.8074 - val_loss: 0.4219 - val_accuracy: 0.8548\n",
            "Epoch 9/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 1.0739 - accuracy: 0.8249 - val_loss: 0.7939 - val_accuracy: 0.7354\n",
            "Epoch 10/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.9910 - accuracy: 0.8395 - val_loss: 0.3183 - val_accuracy: 0.8922\n",
            "Epoch 11/30\n",
            "612/612 [==============================] - 31s 50ms/step - loss: 0.9101 - accuracy: 0.8527 - val_loss: 0.3783 - val_accuracy: 0.8833\n",
            "Epoch 12/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.8248 - accuracy: 0.8668 - val_loss: 0.2843 - val_accuracy: 0.9082\n",
            "Epoch 13/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.7647 - accuracy: 0.8756 - val_loss: 1.0501 - val_accuracy: 0.6964\n",
            "Epoch 14/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.6895 - accuracy: 0.8891 - val_loss: 0.2719 - val_accuracy: 0.9143\n",
            "Epoch 15/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.6625 - accuracy: 0.8961 - val_loss: 0.6603 - val_accuracy: 0.8041\n",
            "Epoch 16/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.6318 - accuracy: 0.8986 - val_loss: 0.3224 - val_accuracy: 0.8945\n",
            "Epoch 17/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.6060 - accuracy: 0.9045 - val_loss: 0.3646 - val_accuracy: 0.8906\n",
            "Epoch 18/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.5695 - accuracy: 0.9093 - val_loss: 0.2511 - val_accuracy: 0.9186\n",
            "Epoch 19/30\n",
            "612/612 [==============================] - 31s 50ms/step - loss: 0.5251 - accuracy: 0.9137 - val_loss: 0.3963 - val_accuracy: 0.8839\n",
            "Epoch 20/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.5083 - accuracy: 0.9176 - val_loss: 0.2597 - val_accuracy: 0.9219\n",
            "Epoch 21/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.4863 - accuracy: 0.9229 - val_loss: 0.2836 - val_accuracy: 0.9157\n",
            "Epoch 22/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.4785 - accuracy: 0.9229 - val_loss: 0.2682 - val_accuracy: 0.9246\n",
            "Epoch 23/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.4468 - accuracy: 0.9280 - val_loss: 0.3359 - val_accuracy: 0.9027\n",
            "Epoch 24/30\n",
            "612/612 [==============================] - 31s 50ms/step - loss: 0.4440 - accuracy: 0.9314 - val_loss: 0.7288 - val_accuracy: 0.8287\n",
            "Epoch 25/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.4315 - accuracy: 0.9327 - val_loss: 0.2431 - val_accuracy: 0.9266\n",
            "Epoch 26/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.4193 - accuracy: 0.9320 - val_loss: 0.1763 - val_accuracy: 0.9447\n",
            "Epoch 27/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.4053 - accuracy: 0.9365 - val_loss: 0.2108 - val_accuracy: 0.9365\n",
            "Epoch 28/30\n",
            "612/612 [==============================] - 30s 50ms/step - loss: 0.3937 - accuracy: 0.9376 - val_loss: 0.2484 - val_accuracy: 0.9240\n",
            "Epoch 29/30\n",
            "612/612 [==============================] - 31s 50ms/step - loss: 0.3530 - accuracy: 0.9423 - val_loss: 0.1879 - val_accuracy: 0.9462\n",
            "Epoch 30/30\n",
            "612/612 [==============================] - 30s 49ms/step - loss: 0.3684 - accuracy: 0.9420 - val_loss: 0.2112 - val_accuracy: 0.9378\n",
            "End: Training of network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xETVmVoM2nJJ",
        "colab_type": "code",
        "outputId": "67c2932d-795a-4466-8484-78eb379d6933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "# Evaluatiing the network on the test set\n",
        "print(\"Start: Evaluate network\")\n",
        "predictions = model.predict(testXF, batch_size=BS)\n",
        "print(classification_report(testYF.argmax(axis=1), predictions.argmax(axis=1),target_names=labelNames))\n",
        "print(\"End: Evaluate network\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Evaluate network\n",
            "                                                    precision    recall  f1-score   support\n",
            "\n",
            "                              Speed limit (20km/h)       0.41      0.98      0.58        60\n",
            "                              Speed limit (30km/h)       0.95      0.86      0.91       720\n",
            "                              Speed limit (50km/h)       0.97      0.92      0.94       750\n",
            "                              Speed limit (60km/h)       0.90      0.93      0.91       450\n",
            "                              Speed limit (70km/h)       0.98      0.95      0.96       660\n",
            "                              Speed limit (80km/h)       0.92      0.87      0.90       630\n",
            "                       End of speed limit (80km/h)       0.98      0.83      0.90       150\n",
            "                             Speed limit (100km/h)       0.92      0.80      0.85       450\n",
            "                             Speed limit (120km/h)       0.78      0.98      0.87       450\n",
            "                                        No passing       0.98      0.99      0.98       480\n",
            "      No passing for vehicles over 3.5 metric tons       0.99      0.99      0.99       660\n",
            "             Right-of-way at the next intersection       0.97      0.95      0.96       420\n",
            "                                     Priority road       1.00      0.95      0.97       690\n",
            "                                             Yield       1.00      1.00      1.00       720\n",
            "                                              Stop       1.00      0.99      0.99       270\n",
            "                                       No vehicles       0.96      0.99      0.97       210\n",
            "          Vehicles over 3.5 metric tons prohibited       0.97      1.00      0.99       150\n",
            "                                          No entry       1.00      1.00      1.00       360\n",
            "                                   General caution       0.97      0.84      0.90       390\n",
            "                       Dangerous curve to the left       0.67      1.00      0.81        60\n",
            "                      Dangerous curve to the right       0.76      1.00      0.86        90\n",
            "                                      Double curve       0.82      0.61      0.70        90\n",
            "                                        Bumpy road       0.93      0.92      0.92       120\n",
            "                                     Slippery road       0.95      0.93      0.94       150\n",
            "                         Road narrows on the right       0.88      0.98      0.93        90\n",
            "                                         Road work       0.95      0.97      0.96       480\n",
            "                                   Traffic signals       0.83      0.98      0.90       180\n",
            "                                       Pedestrians       0.80      1.00      0.89        60\n",
            "                                 Children crossing       0.99      0.84      0.91       150\n",
            "                                 Bicycles crossing       0.83      0.99      0.90        90\n",
            "                                Beware of ice/snow       0.86      0.63      0.73       150\n",
            "                             Wild animals crossing       0.91      0.98      0.94       270\n",
            "               End of all speed and passing limits       0.92      1.00      0.96        60\n",
            "                                  Turn right ahead       0.98      1.00      0.99       210\n",
            "                                   Turn left ahead       1.00      1.00      1.00       120\n",
            "                                        Ahead only       1.00      0.97      0.98       390\n",
            "                              Go straight or right       0.98      1.00      0.99       120\n",
            "                               Go straight or left       1.00      0.98      0.99        60\n",
            "                                        Keep right       0.99      0.97      0.98       690\n",
            "                                         Keep left       1.00      0.97      0.98        90\n",
            "                              Roundabout mandatory       0.77      0.99      0.86        90\n",
            "                                 End of no passing       0.86      0.92      0.89        60\n",
            "End of no passing by vehicles over 3.5 metric tons       0.77      0.90      0.83        90\n",
            "\n",
            "                                          accuracy                           0.94     12630\n",
            "                                         macro avg       0.91      0.94      0.92     12630\n",
            "                                      weighted avg       0.95      0.94      0.94     12630\n",
            "\n",
            "End: Evaluate network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC7LJPnJ2nJN",
        "colab_type": "code",
        "outputId": "96c7a116-b227-42d7-80f7-a11237161fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# saving the model\n",
        "print(\"Start: Save the model\")\n",
        "model.save(\"output/trafficsignnet.model\")\n",
        "print(\"End: Save the model\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start: Save the model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: output/trafficsignnet.model/assets\n",
            "End: Save the model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7T7uR2v2nJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "N = np.arange(0, NUM_EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.plot()\n",
        "plt.savefig(\"output/plot.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl6on63z2nJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOES NOT WORK\n",
        "# !zip output.zip output\n",
        "# Drivebase =  '/content/drive/My Drive/Colab Notebooks/DLProjects/TrafficSignclassification/Code/'\n",
        "# upload = drive.CreateFile({'title': Drivebase + 'lalalal.zip'})\n",
        "# upload.SetContentFile('output.zip')\n",
        "# upload.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3gcrhjdLyyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir $DriveOutputFolder\n",
        "!ls $DriveOutputFolder\n",
        "!ls /content/output\n",
        "!cp -r $OutputFolder $DriveOutputFolder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1S0tzFvevtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}